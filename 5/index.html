<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 5: Fun with Diffusion Models</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Project 5: Fun with Diffusion Models</h1>
            <p class="subtitle">CS180 • Diffusion Models and Image Generation</p>
        </header>
        
        <div style="padding: 20px;">
            <a href="../index.html">← Back to Portfolio</a>
        </div>

        <main>

            <!-- Part A Header -->
            <div class="project-content">
                <h2 style="text-align: center; font-size: 2em; margin: 40px 0;">Part A: The Power of Diffusion Models</h2>
            </div>

            <!-- Part 0: Setup -->
            <div class="project-content">
                <h2>Part 0: Setup and Text Prompts</h2>
                <div class="project-content-body">
                    
                    
                    <h3>Text Prompts and Embeddings</h3>
                    <p><strong>Random Seed Used:</strong> 100 </p>
                    <p>These are my prompts: You have the embeddings for the following prompts
['a high quality photo of a strong blonde woman with blue eyes',
 'a portrait of a college student with straight blonde hair',
 'a photo of a woman weightlifting at the gym',
 'a CrossFit athlete with blonde hair doing a workout',
 'a portrait of a brown-haired woman with green eyes and curly hair',
 'two sisters with different hair colors standing together',
 'a Berkeley student studying computer science',
 'a grey cat sitting peacefully',
 'a tabby cat lounging in sunlight',
 'two cats playing together',
 'a fluffy grey cat portrait',
 'a striped tabby cat looking at camera',
 'a CrossFit gym with equipment',
 'a woman doing a snatch in a CrossFit gym',
 'a Formula 1 race car on the track',
 'an F1 car speeding around a corner',
 'a Formula 1 paddock scene',
 'a woman playing video games',
 'an Overwatch character in action',
 'UC Berkeley campus with the Campanile tower',
 'Sather Tower at UC Berkeley',
 'a computer science classroom',
 'a student studying French in a library',
 'the Berkeley campus on a sunny day',
 'a cornflower blue gradient background',
 'an oil painting of a sunset',
 'a watercolor painting of flowers',
 'a lithograph of a waterfall',
 'an oil painting of an old man',
 'an oil painting of people around a campfire',
 'a rocket ship launching into space',
 'a lighthouse on a cliff',
 'a skull',
 'a waterfall in a forest',
 'a peaceful mountain landscape',
 'a busy city street at night',
 'a cat face close up',
 'a tiger in the jungle',
 'the Eiffel Tower',
 'the Golden Gate Bridge',
 'a coffee cup on a table',
 'a book open on a desk',
 'a Formula 1 car in cornflower blue',
 'a CrossFit gym with blue lighting',
 'a grey cat watching a computer screen',
 'a Berkeley student at a CrossFit competition',
 'two sisters watching Formula 1 together',
 'a tabby cat sleeping on a French textbook',
 'a high quality photo',
 'a professional esports tournament',
 'a cozy study space with cats',
 'a sunrise over San Francisco Bay',
 'a vintage Formula 1 poster',
 'a minimalist gym interior',
 'a French café in Paris',
 'a blonde woman studying at a library desk',
 'a blonde woman lifting weights at the gym',
 'a college student reading computer science textbooks',
 'a strong woman doing a deadlift',
 'a woman typing code on a laptop',
 'a CrossFit athlete doing pull-ups',
 'a student with blonde hair in a lecture hall',
 'a woman in workout clothes holding dumbbells',
 'a Berkeley student walking across campus',
 'a woman running on a track',
 'a blonde athlete stretching before a workout',
 'a focused student studying late at night',
 'a woman doing a handstand in a gym',
 'a college student drinking coffee while coding',
 'two sisters working out together',
 'two sisters studying together in a library',
 'a grey cat and a tabby cat cuddling',
 'a blonde woman and a brown-haired woman smiling',
 'a woman in a cornflower blue CrossFit shirt',
 'a Formula 1 driver in a racing suit',
 'an Overwatch player at a gaming setup',
 'a barbell loaded with weights',
 'a laptop showing lines of code',
 'a French language textbook open on a desk',
 'a gym filled with kettlebells and ropes',
 'a bookshelf full of computer science books',
 'a racing helmet on a pit wall',
 'a gaming keyboard with colorful lights',
 'a woman celebrating a personal record lift',
 'a student acing a computer science exam',
 'a peaceful meditation pose in a gym',
 'an intense study session with notes everywhere',
 'a sunrise workout at an outdoor gym',
 'a late night coding session with desk lamp',
 'a victory celebration at a CrossFit competition',
 'a successful project presentation in class',
 '']
                    I was partially inspired by common examples of ananagrams/hybrids I saw online so I knew I would have some to work with if my others don't work, and then I also included my interests of crossfit and video games, and my studying computer science and French, and going to Berkeley. I also have descriptions of myself and my sister, as well as our two pet cats</p>
                    
                    <h3>Sample Generated Images</h3>
                    <p>Below are images generated from my custom text prompts at different inference steps:</p>
                    
                    <h4>Prompt 1: "a Berkeley student studying computer science"</h4>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./0/a Berkeley student studying computer science with num_inference_steps=20 stage 1.png" alt="Berkeley student 20 steps stage 1">
                            <div class="image-caption">20 inference steps - Stage 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./0/a Berkeley student studying computer science with num_inference_steps=20 stage 2.png" alt="Berkeley student 20 steps stage 2">
                            <div class="image-caption">20 inference steps - Stage 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./0/a Berkeley student studying computer science with num_inference_steps=500 stage 1.png" alt="Berkeley student 500 steps stage 1">
                            <div class="image-caption">500 inference steps - Stage 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./0/a Berkeley student studying computer science with num_inference_steps=500 stage 2.png" alt="Berkeley student 500 steps stage 2">
                            <div class="image-caption">500 inference steps - Stage 2</div>
                        </div>
                    </div>

                    <h4>Prompt 2: "a grey cat watching a computer screen"</h4>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./0/a grey cat watching a computer screen with num_inference_steps=20 stage 1.png" alt="Grey cat 20 steps stage 1">
                            <div class="image-caption">20 inference steps - Stage 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./0/a grey cat watching a computer screen with num_inference_steps=20 stage 2.png" alt="Grey cat 20 steps stage 2">
                            <div class="image-caption">20 inference steps - Stage 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./0/a grey cat watching a computer screen with num_inference_steps=500 stage 1.png" alt="Grey cat 500 steps stage 1">
                            <div class="image-caption">500 inference steps - Stage 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./0/a grey cat watching a computer screen with num_inference_steps=500 stage 2.png" alt="Grey cat 500 steps stage 2">
                            <div class="image-caption">500 inference steps - Stage 2</div>
                        </div>
                    </div>

                    <h4>Prompt 3: "two sisters watching Formula 1 together"</h4>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./0/two sisters watching Formula 1 together with num_inference_steps=20 stage 1.png" alt="Sisters F1 20 steps stage 1">
                            <div class="image-caption">20 inference steps - Stage 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./0/two sisters watching Formula 1 together with num_inference_steps=20 stage 2.png" alt="Sisters F1 20 steps stage 2">
                            <div class="image-caption">20 inference steps - Stage 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./0/two sisters watching Formula 1 together with num_inference_steps=500 stage 1.png" alt="Sisters F1 500 steps stage 1">
                            <div class="image-caption">500 inference steps - Stage 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./0/two sisters watching Formula 1 together with num_inference_steps=500 stage 2.png" alt="Sisters F1 500 steps stage 2">
                            <div class="image-caption">500 inference steps - Stage 2</div>
                        </div>
                    </div>

                    <h4>Observations</h4>
                    <p>The more specific or real-world based (berkeley, formula 1) the prompt, the less likeley the model was to be able to adhear to it. For the computer science student at Berkeley, I thought it was interesting that there was nothing suggesting computer science in the images. It was interesting that as we increase the number of inference steps, the details of the person became more realistic (the refelction on the glasses, for example). Also, the B for berkeley appeared on the shirt. For the formula one, as we increased the number of inference steps, we also increased the amountof detail in the women, but it was interesting that the formula one never really appeared much beyond the one woman's shirt rsembling the VCARB livery in the less steps. It is also interesting that the glasses became sort of neon and the colors more vibrant with more steps. For the cat, the alignment with the prompt was pretty good with less inference steps, although the computer screen was blank. As we increased the steps, the image got more detailed, but the screenhad details that don't make as much sense, and the colors seemed oversaturated. Also, the cat is no longer looking at the computer.</p>
                </div>
            </div>

            <!-- Part 1: Sampling Loops -->
            <div class="project-content">
                <h2>Part 1: Sampling Loops</h2>
                <div class="project-content-body">
                    
                    <h3>1.1 Implementing the Forward Process</h3>
                    <pre><code>def forward(im, t):
  """
  Args:
    im : torch tensor of size (1, 3, 64, 64) representing the clean image
    t : integer timestep

  Returns:
    im_noisy : torch tensor of size (1, 3, 64, 64) representing the noisy image at timestep t
  """
  with torch.no_grad():
    # ===== your code here! ====
    a_t = alphas_cumprod[t]
    epsilon = torch.randn_like(im)
    sqrt_a_t = torch.sqrt(a_t)
    sqrt_1_minus_a_t = torch.sqrt(1 - a_t)
    im_noisy = sqrt_a_t * im + sqrt_1_minus_a_t * epsilon

    # ===== end of code ====
  return im_noisy
                    </code></pre>
                    <h4>Noisy Campanile Images</h4>
                    <p>Berkeley Campanile with noise added at different timesteps. As t increases, more noise is added:</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.1/noise level_ 250.png" alt="Noisy at t=250">
                            <div class="image-caption">t=250</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.1/noise level_ 500.png" alt="Noisy at t=500">
                            <div class="image-caption">t=500</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.1/noise level_ 750.png" alt="Noisy at t=750">
                            <div class="image-caption">t=750</div>
                        </div>
                    </div>

                    <h3>1.2 Classical Denoising</h3>
                    <p>Attempting to denoise using Gaussian blur filtering. As we can see, classical methods struggle to effectively denoise these images:</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.2/noisy image level 250.png" alt="Noisy t=250">
                            <div class="image-caption">Noisy Image at t=250</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.2/denoised image level 250.png" alt="Gaussian denoised t=250">
                            <div class="image-caption">Gaussian Blur Denoising at t=250</div>
                        </div>
                    </div>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.2/noisy image level 500.png" alt="Noisy t=500">
                            <div class="image-caption">Noisy Image at t=500</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.2/denoised image level 500.png" alt="Gaussian denoised t=500">
                            <div class="image-caption">Gaussian Blur Denoising at t=500</div>
                        </div>
                    </div>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.2/noisy image level 750.png" alt="Noisy t=750">
                            <div class="image-caption">Noisy Image at t=750</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.2/denoised image level 750.png" alt="Gaussian denoised t=750">
                            <div class="image-caption">Gaussian Blur Denoising at t=750</div>
                        </div>
                    </div>


                    <h3>1.3 One-Step Denoising</h3>
                    <p>Using the pretrained diffusion model UNet for one-step denoising with the prompt "a high quality photo". For each noise level, we show the noisy image and the one-step denoised result:</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.3/im_noisy%20campanilie%20with%20t%3D250.png" alt="Noisy t=250">
                            <div class="image-caption">Noisy Campanile at t=250</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.3/Denoised%20Campanilie%20with%20t%3D250.png" alt="One-step denoised t=250">
                            <div class="image-caption">One-Step Denoised at t=250</div>
                        </div>
                    </div>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.3/im_noisy%20campanilie%20with%20t%3D500.png" alt="Noisy t=500">
                            <div class="image-caption">Noisy Campanile at t=500</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.3/Denoised%20Campanilie%20with%20t%3D500.png" alt="One-step denoised t=500">
                            <div class="image-caption">One-Step Denoised at t=500</div>
                        </div>
                    </div>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.3/im_noisy%20campanilie%20with%20t%3D750.png" alt="Noisy t=750">
                            <div class="image-caption">Noisy Campanile at t=750</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.3/Denoised%20Campanilie%20with%20t%3D750.png" alt="One-step denoised t=750">
                            <div class="image-caption">One-Step Denoised at t=750</div>
                        </div>
                    </div>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.3/orginal%20Campanilie.png" alt="Original Campanile">
                            <div class="image-caption">Original Campanile (for reference)</div>
                        </div>
                    </div>

                    <h3>1.4 Iterative Denoising</h3>
                    <p><strong>Parameters:</strong></p>
                    <ul>
                        <li>Starting index (i_start): 10</li>
                        <li>Stride: 30</li>
                        <li>Timestep range: [990, 960, ..., 0]</li>
                    </ul>

                    <h4>Denoising Progression</h4>
                    <p>Showing the iterative denoising process starting from t=690. Each image shows progressively less noise as we move through the denoising loop (loop_num represents the iteration number):</p>
                    <pre><code>strided_timesteps = list(range(990, -1, -30))
                    
stage_1.scheduler.set_timesteps(timesteps=strided_timesteps)
                    </code></pre>
                    <pre><code>def iterative_denoise(im_noisy, i_start, prompt_embeds, timesteps, display=True):
  image = im_noisy

  with torch.no_grad():
    for i in range(i_start, len(timesteps) - 1):
      # Get timesteps
      t = timesteps[i]
      prev_t = timesteps[i+1]

      # get `alpha_cumprod` and `alpha_cumprod_prev` for timestep t from `alphas_cumprod`
      # compute `alpha`
      # compute `beta`
      # ===== your code here! =====
      alpha_t_bar = alphas_cumprod[t]
      alpha_t_prime_bar = alphas_cumprod[prev_t]
      alpha_t = alpha_t_bar / alpha_t_prime_bar
      beta_t = 1 - alpha_t
      # ==== end of code ====

      # Get noise estimate
      model_output = stage_1.unet(
          image,
          t,
          encoder_hidden_states=prompt_embeds.half().cuda(),
          return_dict=False
      )[0]

      # Split estimate into noise and variance estimate
      noise_est, predicted_variance = torch.split(model_output, image.shape[1], dim=1)

      # compute `pred_prev_image` (x_{t'}), the DDPM estimate for the image at the
      # next timestep, which is slightly less noisy. Use the equation 3.
      # This is the core of DDPM
      # ===== your code here! =====
      sqrt_alpha_t_bar = torch.sqrt(alpha_t_bar)
      sqrt_1_minus_alpha_t_bar = torch.sqrt(1 - alpha_t_bar)
      x_0 = (image - sqrt_1_minus_alpha_t_bar * noise_est) / sqrt_alpha_t_bar
      sqrt_alpha_t_prime_bar = torch.sqrt(alpha_t_prime_bar)
      sqrt_alpha_t = torch.sqrt(alpha_t)
      term1 = (sqrt_alpha_t_prime_bar * beta_t) / (1 - alpha_t_bar) * x_0
      term2 = (sqrt_alpha_t * (1 - alpha_t_prime_bar)) / (1 - alpha_t_bar) * image
      pred_prev_image = add_variance(predicted_variance, t, term1 + term2)

      # ==== end of code ====
      if i % 5 == 0:
        save_images = True
        save_image("A/1/1.4", img_name=f"predicted_img_t_{t}_loop_num_{i}", im = pred_prev_image)
        show_image(pred_prev_image, f"predicted_img_t_{t}_loop_num_{i}")
      image = pred_prev_image

    clean = image.cpu().detach().numpy()
    # if display:
    #   show_image(clean, f"clean with t={t}")
  return clean</code></pre>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.4/predicted_img_t_690_loop_num_10.png" alt="Loop 10">
                            <div class="image-caption">Loop 10 (t=690, most noisy)</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.4/predicted_img_t_540_loop_num_15.png" alt="Loop 15">
                            <div class="image-caption">Loop 15 (t=540)</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.4/predicted_img_t_390_loop_num_20.png" alt="Loop 20">
                            <div class="image-caption">Loop 20 (t=390)</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.4/predicted_img_t_240_loop_num_25.png" alt="Loop 25">
                            <div class="image-caption">Loop 25 (t=240)</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.4/predicted_img_t_90_loop_num_30.png" alt="Loop 30">
                            <div class="image-caption">Loop 30 (t=90, cleanest)</div>
                        </div>
                    </div>

                    <h4>Comparison: Iterative vs One-Step vs Gaussian</h4>
                    <p>Comparing all three denoising methods at t=690:</p>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.4/clean with t=690.png" alt="Iterative final">
                            <div class="image-caption">Iterative Denoising (Best Result)</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.4/clean_one_step with t=690.png" alt="One-step">
                            <div class="image-caption">One-Step Denoising</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.4/blur_filtered with t=690.png" alt="Gaussian">
                            <div class="image-caption">Gaussian Blur</div>
                        </div>
                    </div>

                    <h3>1.5 Diffusion Model Sampling</h3>
                    <p>Generating images from pure noise using the prompt "a high quality photo". These images are created by starting with random noise (t=1000) and iteratively denoising:</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.5/generated_im_0.png" alt="Sample 1">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.5/generated_im_1.png" alt="Sample 2">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.5/generated_im_2.png" alt="Sample 3">
                            <div class="image-caption">Sample 3</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.5/generated_im_3.png" alt="Sample 4">
                            <div class="image-caption">Sample 4</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.5/generated_im_4.png" alt="Sample 5">
                            <div class="image-caption">Sample 5</div>
                        </div>
                    </div>

                    <h3>1.6 Classifier-Free Guidance (CFG)</h3>
                    <p><strong>CFG Scale:</strong> γ = 7</p>
                    <p>Implementing Classifier-Free Guidance using the formula: ε = ε_u + γ(ε_c - ε_u), where ε_c is the conditional noise estimate and ε_u is the unconditional noise estimate. CFG greatly improves image quality at the expense of diversity.</p>
                                        
                    <pre><code>def iterative_denoise_cfg(im_noisy, i_start, prompt_embeds, uncond_prompt_embeds, timesteps, scale=7, display=True):
  image = im_noisy

  with torch.no_grad():
    for i in range(i_start, len(timesteps) - 1):
      # Get timesteps
      t = timesteps[i]
      prev_t = timesteps[i+1]

      # Get `alpha_cumprod`, `alpha_cumprod_prev`, `alpha`, `beta`
      # ===== your code here! =====
      alpha_t_bar = alphas_cumprod[t]
      alpha_t_prime_bar = alphas_cumprod[prev_t]
      alpha_t = alpha_t_bar / alpha_t_prime_bar
      beta_t = 1 - alpha_t
      # ==== end of code ====

      # Get cond noise estimate
      model_output = stage_1.unet(
          image,
          t,
          encoder_hidden_states=prompt_embeds.half().cuda(),
          return_dict=False
      )[0]

      # Get uncond noise estimate
      uncond_model_output = stage_1.unet(
          image,
          t,
          encoder_hidden_states=uncond_prompt_embeds.half().cuda(),
          return_dict=False
      )[0]

      # Split estimate into noise and variance estimate
      noise_est, predicted_variance = torch.split(model_output, image.shape[1], dim=1)
      uncond_noise_est, _ = torch.split(uncond_model_output, image.shape[1], dim=1)

      # Compute the CFG noise estimate based on equation 4
      # ===== your code here! =====
      cfg_noise = uncond_noise_est + scale * (noise_est - uncond_noise_est)
      # ==== end of code ====


      # Get `pred_prev_image`, the next less noisy image.
      # ===== your code here! =====
      sqrt_alpha_t_bar = torch.sqrt(alpha_t_bar)
      sqrt_1_minus_alpha_t_bar = torch.sqrt(1 - alpha_t_bar)
      x_0 = (image - sqrt_1_minus_alpha_t_bar * cfg_noise) / sqrt_alpha_t_bar
      sqrt_alpha_t_prime_bar = torch.sqrt(alpha_t_prime_bar)
      sqrt_alpha_t = torch.sqrt(alpha_t)
      term1 = (sqrt_alpha_t_prime_bar * beta_t) / (1 - alpha_t_bar) * x_0
      term2 = (sqrt_alpha_t * (1 - alpha_t_prime_bar)) / (1 - alpha_t_bar) * image
      pred_prev_image = add_variance(predicted_variance, t, term1 + term2)
      # ==== end of code ====

      image = pred_prev_image

    clean = image.cpu().detach().numpy()

  return clean</code></pre>

                    <h4>Improved Samples with CFG</h4>
                    <p>These images are generated with CFG scale of 7, showing dramatically improved quality:</p>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.6/generated_im_0.png" alt="CFG Sample 1">
                            <div class="image-caption">CFG Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.6/generated_im_1.png" alt="CFG Sample 2">
                            <div class="image-caption">CFG Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.6/generated_im_2.png" alt="CFG Sample 3">
                            <div class="image-caption">CFG Sample 3</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.6/generated_im_3.png" alt="CFG Sample 4">
                            <div class="image-caption">CFG Sample 4</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.6/generated_im_4.png" alt="CFG Sample 5">
                            <div class="image-caption">CFG Sample 5</div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Part 1.7: Image-to-Image Translation -->
            <div class="project-content">
                <h3>SDEdit on Test Images</h3>
                    <p>Using SDEdit to project images onto the natural image manifold with the conditioning prompt "a high quality photo". The more noise we add (lower i_start values), the larger the edits become.</p>
                    
                    <h4>Campanile Edits</h4>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/denoised_campaniele_i_start_1.png" alt="i_start=1">
                            <div class="image-caption">i_start=1</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/denoised_campaniele_i_start_3.png" alt="i_start=3">
                            <div class="image-caption">i_start=3</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/denoised_campaniele_i_start_5.png" alt="i_start=5">
                            <div class="image-caption">i_start=5</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/denoised_campaniele_i_start_7.png" alt="i_start=7">
                            <div class="image-caption">i_start=7</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/denoised_campaniele_i_start_10.png" alt="i_start=10">
                            <div class="image-caption">i_start=10</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/denoised_campaniele_i_start_20.png" alt="i_start=20">
                            <div class="image-caption">i_start=20</div>
                        </div>
                    </div>

            <!-- Part 1.7.1: Hand-Drawn and Web Images -->
            <div class="project-content">
                <h2>Part 1.7.1: Editing Hand-Drawn and Web Images</h2>
                <div class="project-content-body">
                    
                    <h3>Web Image</h3>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/1/web_im.png" alt="Web image original">
                            <div class="image-caption">Original Web Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/web_i_start1.png" alt="i_start=1">
                            <div class="image-caption">i_start=1</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/web_i_start3.png" alt="i_start=3">
                            <div class="image-caption">i_start=3</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/web_i_start5.png" alt="i_start=5">
                            <div class="image-caption">i_start=5</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/web_i_start7.png" alt="i_start=7">
                            <div class="image-caption">i_start=7</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/web_i_start10.png" alt="i_start=10">
                            <div class="image-caption">i_start=10</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/web_i_start20.png" alt="i_start=20">
                            <div class="image-caption">i_start=20</div>
                        </div>
                    </div>

                    <h3>Hand-Drawn Image 1: Castle</h3>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_castle.png" alt="Drawing 1 original">
                            <div class="image-caption">Original Drawing: Castle</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_castle_start_1.png" alt="i_start=1">
                            <div class="image-caption">i_start=1</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_castle_start_3.png" alt="i_start=3">
                            <div class="image-caption">i_start=3</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_castle_start_5.png" alt="i_start=5">
                            <div class="image-caption">i_start=5</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_castle_start_7.png" alt="i_start=7">
                            <div class="image-caption">i_start=7</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_castle_start_10.png" alt="i_start=10">
                            <div class="image-caption">i_start=10</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_castle_start_20.png" alt="i_start=20">
                            <div class="image-caption">i_start=20</div>
                        </div>
                    </div>

                    <h3>Hand-Drawn Image 2: Tree</h3>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_tree.png" alt="Drawing 2 original">
                            <div class="image-caption">Original Drawing: Tree</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_tree_start_1.png" alt="i_start=1">
                            <div class="image-caption">i_start=1</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_tree_start_3.png" alt="i_start=3">
                            <div class="image-caption">i_start=3</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_tree_start_5.png" alt="i_start=5">
                            <div class="image-caption">i_start=5</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_tree_start_7.png" alt="i_start=7">
                            <div class="image-caption">i_start=7</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_tree_start_10.png" alt="i_start=10">
                            <div class="image-caption">i_start=10</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/1/hand_drawn_tree_start_20.png" alt="i_start=20">
                            <div class="image-caption">i_start=20</div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Part 1.7.2: Inpainting -->
            <div class="project-content">
                <h2>Part 1.7.2: Inpainting</h2>
                <div class="project-content-body">
                    <p>Implementing inpainting using the RePaint algorithm. At each denoising step, we replace the unmasked regions with the original image (with appropriate noise added), while allowing the model to generate content in the masked regions.</p>
                    <p><strong>Formula:</strong> x_t ← m·x_t + (1-m)·forward(x_orig, t)</p>
                    <pre><code>def inpaint(original_image, mask, prompt_embeds, uncond_prompt_embeds, timesteps, scale=7, display=True):
  image = torch.randn_like(original_image).to(device).half()
  original_image = original_image.to(device).half()
  mask = mask.to(device).half()
    # use your previous `iterative_denoise_cfg` function and make the appropriate changes
  with torch.no_grad():
    for i in range(0, len(timesteps) - 1):
      # Get timesteps
      t = timesteps[i]
      prev_t = timesteps[i+1]

      # Get `alpha_cumprod`, `alpha_cumprod_prev`, `alpha`, `beta`
      # ===== your code here! =====
      alpha_t_bar = alphas_cumprod[t]
      alpha_t_prime_bar = alphas_cumprod[prev_t]
      alpha_t = alpha_t_bar / alpha_t_prime_bar
      beta_t = 1 - alpha_t
      # ==== end of code ====

      # Get cond noise estimate
      model_output = stage_1.unet(
          image,
          t,
          encoder_hidden_states=prompt_embeds.half().cuda(),
          return_dict=False
      )[0]

      # Get uncond noise estimate
      uncond_model_output = stage_1.unet(
          image,
          t,
          encoder_hidden_states=uncond_prompt_embeds.half().cuda(),
          return_dict=False
      )[0]

      # Split estimate into noise and variance estimate
      noise_est, predicted_variance = torch.split(model_output, image.shape[1], dim=1)
      uncond_noise_est, _ = torch.split(uncond_model_output, image.shape[1], dim=1)

      # Compute the CFG noise estimate based on equation 4
      # ===== your code here! =====
      cfg_noise = uncond_noise_est + scale * (noise_est - uncond_noise_est)
      # ==== end of code ====


      # Get `pred_prev_image`, the next less noisy image.
      # ===== your code here! =====
      sqrt_alpha_t_bar = torch.sqrt(alpha_t_bar)
      sqrt_1_minus_alpha_t_bar = torch.sqrt(1 - alpha_t_bar)
      x_0 = (image - sqrt_1_minus_alpha_t_bar * cfg_noise) / sqrt_alpha_t_bar
      sqrt_alpha_t_prime_bar = torch.sqrt(alpha_t_prime_bar)
      sqrt_alpha_t = torch.sqrt(alpha_t)
      term1 = (sqrt_alpha_t_prime_bar * beta_t) / (1 - alpha_t_bar) * x_0
      term2 = (sqrt_alpha_t * (1 - alpha_t_prime_bar)) / (1 - alpha_t_bar) * image
      pred_prev_image = add_variance(predicted_variance, t, term1 + term2)
      # ==== end of code ====
      # noisy_original = forward(original_image.cpu(), prev_t)
      if t == len(timesteps) - 2:
        noisy_original = forward(original_image.cpu(), t)
      else:
        noisy_original = forward(original_image.cpu(), prev_t)

      noisy_original = noisy_original.to(device).half()
      pred_prev_image = mask * pred_prev_image + (1 - mask) * noisy_original
      image = pred_prev_image

    clean = image.cpu().detach().numpy()

  return clean</code></pre>
                    
                    <h3>Campanile Inpainting</h3>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/2/campanile_inpainted.png" alt="Inpainted result">
                            <div class="image-caption">Campanile Inpainted Result</div>
                        </div>
                    </div>

                    <h3>Boggle Image Inpainting</h3>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/2/boggle_original.png" alt="Original">
                            <div class="image-caption">Original Boggle</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/2/boggle_mask.png" alt="Mask">
                            <div class="image-caption">Inpainting Mask</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/2/inpainted_boggle.png" alt="Inpainted result">
                            <div class="image-caption">Inpainted Result</div>
                        </div>
                    </div>

                    <h3>Mug Image Inpainting</h3>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/2/mug_original.png" alt="Original mug">
                            <div class="image-caption">Original Mug</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/2/mug_mask.png" alt="Mask">
                            <div class="image-caption">Inpainting Mask</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/2/mug_inpainted.png" alt="Inpainted result">
                            <div class="image-caption">Inpainted Result</div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Part 1.7.3: Text-Conditional Image-to-Image -->
            <div class="project-content">
                <h2>Part 1.7.3: Text-Conditional Image-to-Image Translation</h2>
                <div class="project-content-body">
                    <p>Now using custom text prompts to guide the projection, rather than just "a high quality photo". This gives us more control over the style and content of the generated images.</p>
                    
                    <h3>Campanile with Custom Prompt: "an oil painting of a sunset"</h3>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/3/sunset_to_campanielle_i_start_1.png" alt="i_start=1">
                            <div class="image-caption">i_start=1</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/sunset_to_campanielle_i_start_3.png" alt="i_start=3">
                            <div class="image-caption">i_start=3</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/sunset_to_campanielle_i_start_5.png" alt="i_start=5">
                            <div class="image-caption">i_start=5</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/sunset_to_campanielle_i_start_7.png" alt="i_start=7">
                            <div class="image-caption">i_start=7</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/sunset_to_campanielle_i_start_10.png" alt="i_start=10">
                            <div class="image-caption">i_start=10</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/sunset_to_campanielle_i_start_20.png" alt="i_start=20">
                            <div class="image-caption">i_start=20</div>
                        </div>
                    </div>

                    <h3>Photo of my cat with Custom Prompt: "a Formula 1 race car on the track"</h3>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/3/f1_to_boggle_i_start_1.png" alt="i_start=1">
                            <div class="image-caption">i_start=1</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/f1_to_boggle_i_start_3.png" alt="i_start=3">
                            <div class="image-caption">i_start=3</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/f1_to_boggle_i_start_5.png" alt="i_start=5">
                            <div class="image-caption">i_start=5</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/f1_to_boggle_i_start_7.png" alt="i_start=7">
                            <div class="image-caption">i_start=7</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/f1_to_boggle_i_start_10.png" alt="i_start=10">
                            <div class="image-caption">i_start=10</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/f1_to_boggle_i_start_20.png" alt="i_start=20">
                            <div class="image-caption">i_start=20</div>
                        </div>
                    </div>
                    <h3>Photo of a mug with Custom Prompt: "a CrossFit athlete with blonde hair doing a workout"</h3>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.7/3/crossfit_to_mug_i_start_1.png" alt="i_start=1">
                            <div class="image-caption">i_start=1</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/crossfit_to_mug_i_start_3.png" alt="i_start=3">
                            <div class="image-caption">i_start=3</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/crossfit_to_mug_i_start_5.png" alt="i_start=5">
                            <div class="image-caption">i_start=5</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/crossfit_to_mug_i_start_7.png" alt="i_start=7">
                            <div class="image-caption">i_start=7</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/crossfit_to_mug_i_start_10.png" alt="i_start=10">
                            <div class="image-caption">i_start=10</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.7/3/crossfit_to_mug_i_start_20.png" alt="i_start=20">
                            <div class="image-caption">i_start=20</div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Part 1.8: Visual Anagrams -->
            <div class="project-content">
                <h2>Part 1.8: Visual Anagrams</h2>
                <div class="project-content-body">
                    <p>Creating optical illusions where an image shows one thing right-side up and something completely different when flipped upside down!</p>
                    <p><strong>Algorithm:</strong> ε₁ = CFG of UNet(x_t, t, p₁), ε₂ = flip(CFG of UNet(flip(x_t), t, p₂)), ε = (ε₁ + ε₂)/2</p>
                    <pre><code>def make_flip_illusion(image, i_start, prompt_embeds, uncond_prompt_embeds, timesteps, scale=7, display=True):
  p1 = prompt_embeds[0]
  p2 = prompt_embeds[1]
  with torch.no_grad():
    for i in range(i_start, len(timesteps) - 1):
      t = timesteps[i]
      prev_t = timesteps[i+1]
      alpha_t_bar = alphas_cumprod[t]
      alpha_t_prime_bar = alphas_cumprod[prev_t]
      alpha_t = alpha_t_bar / alpha_t_prime_bar
      beta_t = 1 - alpha_t

      cond_output_1 = stage_1.unet(
          image,
          t,
          encoder_hidden_states=p1.half().cuda(),
          return_dict=False
      )[0]
      uncond_output_1 = stage_1.unet(
          image,
          t,
          encoder_hidden_states=uncond_prompt_embeds.half().cuda(),
          return_dict=False
      )[0]
      noise_est_1, predicted_variance_1 = torch.split(cond_output_1, image.shape[1], dim=1)
      uncond_noise_1, _ = torch.split(uncond_output_1, image.shape[1], dim=1)
      epsilon_1 = uncond_noise_1 + scale * (noise_est_1 - uncond_noise_1)

      image_flipped = torch.flip(image, dims=[2])
      cond_output_2 = stage_1.unet(
          image_flipped,
          t,
          encoder_hidden_states=p2.half().cuda(),
          return_dict=False
      )[0]
      uncond_output_2 = stage_1.unet(
          image_flipped,
          t,
          encoder_hidden_states=uncond_prompt_embeds.half().cuda(),
          return_dict=False
      )[0]
      noise_est_2, predicted_variance_2 = torch.split(cond_output_2, image.shape[1], dim=1)
      uncond_noise_2, _ = torch.split(uncond_output_2, image.shape[1], dim=1)
      epsilon_2 = uncond_noise_2 + scale * (noise_est_2 - uncond_noise_2)

      #now we need to reverse /flip al of the 2 stuff
      epsilon_2 = torch.flip(epsilon_2, dims=[2])
      epsilon = (epsilon_1 + epsilon_2) / 2

      sqrt_alpha_t_bar = torch.sqrt(alpha_t_bar)
      sqrt_1_minus_alpha_t_bar = torch.sqrt(1 - alpha_t_bar)
      x_0 = (image - sqrt_1_minus_alpha_t_bar * epsilon) / sqrt_alpha_t_bar
      sqrt_alpha_t_prime_bar = torch.sqrt(alpha_t_prime_bar)
      sqrt_alpha_t = torch.sqrt(alpha_t)
      term1 = (sqrt_alpha_t_prime_bar * beta_t) / (1 - alpha_t_bar) * x_0
      term2 = (sqrt_alpha_t * (1 - alpha_t_prime_bar)) / (1 - alpha_t_bar) * image
      pred_prev_image = add_variance(predicted_variance_1, t, term1 + term2)
      image = pred_prev_image
  return image.cpu()</code></pre>
                    
                    <h3>Visual Anagram 1: Eiffel tower and golden gate bridge</h3>
                    <p><strong>Prompt 1 (normal):</strong> "the Eiffel Tower"</p>
                    <p><strong>Prompt 2 (upside down):</strong> "the Golden Gate Bridge"</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.8/eiffel_to_bridge_normal.png" alt="Anagram normal">
                            <div class="image-caption">Normal View</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.8/eiffel_to_bridge_normal.png" alt="Anagram flipped" style="transform: rotate(180deg);">
                            <div class="image-caption">Flipped 180° View</div>
                        </div>
                    </div>

                    <h3>Visual Anagram 2: Studying to Gym</h3>
                    <p><strong>Prompt 1 (normal):</strong> "a blonde woman lifting weights at the gym"</p>
                    <p><strong>Prompt 2 (upside down):</strong> "a blonde woman studying at a library desk"</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.8/studying_to_gym.png" alt="Anagram normal">
                            <div class="image-caption">Normal View</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.8/studying_to_gym.png" alt="Anagram flipped" style="transform: rotate(180deg);">
                            <div class="image-caption">Flipped 180° View</div>
                        </div>
                    </div>


                    <h3>Visual Anagram 4: Laptop</h3>
                    <p><strong>Prompt 1 (normal):</strong> "a laptop showing lines of code"</p>
                    <p><strong>Prompt 2 (upside down):</strong> "a French language textbook open on a desk"</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./1.8/laptop.png" alt="Anagram normal">
                            <div class="image-caption">Normal View</div>
                        </div>
                        <div class="image-container">
                            <img src="./1.8/laptop.png" alt="Anagram flipped" style="transform: rotate(180deg);">
                            <div class="image-caption">Flipped 180° View</div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Part 1.9: Hybrid Images -->
            <div class="project-content">
                <h2>Part 1.9: Hybrid Images</h2>
                <div class="project-content-body">
                    <p>Implementing Factorized Diffusion to create hybrid images. We combine low frequencies from one noise estimate with high frequencies from another, similar to Project 2!</p>
                    <pre><code>def make_hybrids(image, i_start, prompt_embeds, uncond_prompt_embeds, timesteps, scale=7, display=True):
  p1 = prompt_embeds[0]
  p2 = prompt_embeds[1]
  with torch.no_grad():
    for i in range(i_start, len(timesteps) - 1):
      t = timesteps[i]
      prev_t = timesteps[i+1]
      alpha_t_bar = alphas_cumprod[t]
      alpha_t_prime_bar = alphas_cumprod[prev_t]
      alpha_t = alpha_t_bar / alpha_t_prime_bar
      beta_t = 1 - alpha_t

      cond_output_1 = stage_1.unet(
          image,
          t,
          encoder_hidden_states=p1.half().cuda(),
          return_dict=False
      )[0]
      uncond_output_1 = stage_1.unet(
          image,
          t,
          encoder_hidden_states=uncond_prompt_embeds.half().cuda(),
          return_dict=False
      )[0]
      noise_est_1, predicted_variance_1 = torch.split(cond_output_1, image.shape[1], dim=1)
      uncond_noise_1, _ = torch.split(uncond_output_1, image.shape[1], dim=1)
      epsilon_1 = uncond_noise_1 + scale * (noise_est_1 - uncond_noise_1)

      cond_output_2 = stage_1.unet(
          image,
          t,
          encoder_hidden_states=p2.half().cuda(),
          return_dict=False
      )[0]
      uncond_output_2 = stage_1.unet(
          image,
          t,
          encoder_hidden_states=uncond_prompt_embeds.half().cuda(),
          return_dict=False
      )[0]
      noise_est_2, predicted_variance_2 = torch.split(cond_output_2, image.shape[1], dim=1)
      uncond_noise_2, _ = torch.split(uncond_output_2, image.shape[1], dim=1)
      epsilon_2 = uncond_noise_2 + scale * (noise_est_2 - uncond_noise_2)

      #now we need to lowpass/high pass
      epsilon = lowpass(epsilon_1) + highpass(epsilon_2)

      sqrt_alpha_t_bar = torch.sqrt(alpha_t_bar)
      sqrt_1_minus_alpha_t_bar = torch.sqrt(1 - alpha_t_bar)
      x_0 = (image - sqrt_1_minus_alpha_t_bar * epsilon) / sqrt_alpha_t_bar
      sqrt_alpha_t_prime_bar = torch.sqrt(alpha_t_prime_bar)
      sqrt_alpha_t = torch.sqrt(alpha_t)
      term1 = (sqrt_alpha_t_prime_bar * beta_t) / (1 - alpha_t_bar) * x_0
      term2 = (sqrt_alpha_t * (1 - alpha_t_prime_bar)) / (1 - alpha_t_bar) * image
      pred_prev_image = add_variance(predicted_variance_1, t, term1 + term2)
      image = pred_prev_image
  return image.cpu()
</code></pre>
                    <p><strong>Parameters:</strong></p>
                    <ul>
                        <li>Gaussian kernel size: 33</li>
                        <li>Sigma: 2</li>
                    </ul>
                    <p><strong>Formula:</strong> ε = f_lowpass(ε₁) + f_highpass(ε₂)</p>
                    
                    <h3>Hybrid Image 1: Cat & Tiger</h3>
                    <p><strong>Low Frequency Prompt:</strong> 'a grey cat sitting peacefully'</p>
                    <p><strong>High Frequency Prompt:</strong> 'a tiger in the jungle'</p>
                    
                    <div class="image-gallery">
                        <div class="image-container" style="max-width: 600px; margin: 0 auto;">
                            <img src="./1.9/cat_tiger_hybrid.png" alt="Cat Tiger Hybrid">
                            <div class="image-caption">Hybrid Image: Cat (far) & Tiger (near)</div>
                        </div>
                    </div>

                    <h3>Hybrid Image 2: Coffee & Book</h3>
                    <p><strong>Low Frequency Prompt:</strong> 'a coffee cup on a table'</p>
                    <p><strong>High Frequency Prompt:</strong> 'a book open on a desk'</p>
                    
                    <div class="image-gallery">
                        <div class="image-container" style="max-width: 600px; margin: 0 auto;">
                            <img src="./1.9/coffee_book_hybrid.png" alt="Coffee Book Hybrid">
                            <div class="image-caption">Hybrid Image: Coffee (far) & Book (near)</div>
                        </div>
                    </div>

                </div>
            </div>

            <!-- Part B: Flow Matching from Scratch -->
            <div class="project-content">
                <h2>Part B: Flow Matching from Scratch!</h2>
                <div class="project-content-body">
                    <p>In Part B, we train our own flow matching model on MNIST to generate handwritten digits from scratch. This involves building and training a UNet architecture with time and class conditioning.</p>
                </div>
            </div>

            <!-- Part 1: Single-Step Denoising UNet -->
            <div class="project-content">
                <h2>Part 1: Training a Single-Step Denoising UNet</h2>
                <div class="project-content-body">
                    
                    <h3>1.1 Implementing the UNet</h3>
                    <p>[Explain the UNet architecture implementation with downsampling and upsampling blocks]</p>
                    
                    <h3>1.2 Using the UNet to Train a Denoiser</h3>
                    
                    <h4>Visualizing the Noising Process</h4>
                    <p>Visualization of adding different levels of noise (σ) to clean MNIST images. We take the same clean digit and progressively add more Gaussian noise according to the formula: z = x + σε, where ε ~ N(0, I).</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2/Sigma=0.0.png" alt="Sigma 0.0">
                            <div class="image-caption">σ = 0.0 (Clean, no noise)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2/Sigma=0.2.png" alt="Sigma 0.2">
                            <div class="image-caption">σ = 0.2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2/Sigma=0.4.png" alt="Sigma 0.4">
                            <div class="image-caption">σ = 0.4</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2/Sigma=0.5.png" alt="Sigma 0.5">
                            <div class="image-caption">σ = 0.5 (Training level)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2/Sigma=0.6.png" alt="Sigma 0.6">
                            <div class="image-caption">σ = 0.6</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2/Sigma=0.8.png" alt="Sigma 0.8">
                            <div class="image-caption">σ = 0.8</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2/Sigma=1.0.png" alt="Sigma 1.0">
                            <div class="image-caption">σ = 1.0 (Maximum noise)</div>
                        </div>
                    </div>

                    <p><strong>Observations:</strong> As σ increases, more noise is added to the image, making the digit progressively harder to recognize. At σ = 0.0, we see the original clean digit. By σ = 1.0, the image is almost entirely dominated by noise and the digit is barely visible.</p>

                    <h4>1.2.1 Training</h4>
                    <p><strong>Training Details:</strong></p>
                    <ul>
                        <li>Dataset: MNIST training set</li>
                        <li>Batch size: 256</li>
                        <li>Hidden dimension D: 128</li>
                        <li>Optimizer: Adam (lr=1e-4)</li>
                        <li>Epochs: 5</li>
                        <li>Noise level: σ = 0.5</li>
                    </ul>

                    <h5>Training Loss Curve</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/model_training_loss_curve.png" alt="Training loss">
                            <div class="image-caption">Training Loss over Iterations (5 Epochs)</div>
                        </div>
                    </div>

                    <h5>Denoising Results after Epoch 1</h5>
                    <p>Sample results on test set with σ = 0.5 after 1 epoch of training. For each sample, we show: Clean digit → Noisy (σ=0.5) → Denoised. Early training shows the model is learning but digits are still somewhat blurry:</p>
                    
                    <h6>Sample 0 - Epoch 1</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_0_epoch_1.png" alt="Clean 0 epoch 1">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_0_sigma_0.5_epoch_1.png" alt="Noisy 0 epoch 1">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_0_epoch_1.png" alt="Denoised 0 epoch 1">
                            <div class="image-caption">Denoised (Epoch 1)</div>
                        </div>
                    </div>

                    <h6>Sample 1 - Epoch 1</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_1_epoch_1.png" alt="Clean 1 epoch 1">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_1_sigma_0.5_epoch_1.png" alt="Noisy 1 epoch 1">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_1_epoch_1.png" alt="Denoised 1 epoch 1">
                            <div class="image-caption">Denoised (Epoch 1)</div>
                        </div>
                    </div>

                    <h6>Sample 2 - Epoch 1</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_2_epoch_1.png" alt="Clean 2 epoch 1">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_2_sigma_0.5_epoch_1.png" alt="Noisy 2 epoch 1">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_2_epoch_1.png" alt="Denoised 2 epoch 1">
                            <div class="image-caption">Denoised (Epoch 1)</div>
                        </div>
                    </div>

                    <h6>Sample 3 - Epoch 1</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_3_epoch_1.png" alt="Clean 3 epoch 1">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_3_sigma_0.5_epoch_1.png" alt="Noisy 3 epoch 1">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_3_epoch_1.png" alt="Denoised 3 epoch 1">
                            <div class="image-caption">Denoised (Epoch 1)</div>
                        </div>
                    </div>

                    <h6>Sample 4 - Epoch 1</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_4_epoch_1.png" alt="Clean 4 epoch 1">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_4_sigma_0.5_epoch_1.png" alt="Noisy 4 epoch 1">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_4_epoch_1.png" alt="Denoised 4 epoch 1">
                            <div class="image-caption">Denoised (Epoch 1)</div>
                        </div>
                    </div>

                    <p><strong>Epoch 1 Observations:</strong> After just 1 epoch, the model has learned to remove significant noise but the denoised images are still somewhat blurry and lack fine detail. The general shape and digit class are recognizable, demonstrating that the UNet is learning the denoising task.</p>

                    <h5>Denoising Results after Epoch 5</h5>
                    <p>After 5 epochs of training, the denoising quality is significantly improved. The model produces much sharper and cleaner digits:</p>
                    
                    <h6>Sample 0 - Epoch 5</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_0_epoch_5.png" alt="Clean 0 epoch 5">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_0_sigma_0.5_epoch_5.png" alt="Noisy 0 epoch 5">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_0_epoch_5.png" alt="Denoised 0 epoch 5">
                            <div class="image-caption">Denoised (Epoch 5)</div>
                        </div>
                    </div>

                    <h6>Sample 1 - Epoch 5</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_1_epoch_5.png" alt="Clean 1 epoch 5">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_1_sigma_0.5_epoch_5.png" alt="Noisy 1 epoch 5">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_1_epoch_5.png" alt="Denoised 1 epoch 5">
                            <div class="image-caption">Denoised (Epoch 5)</div>
                        </div>
                    </div>

                    <h6>Sample 2 - Epoch 5</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_2_epoch_5.png" alt="Clean 2 epoch 5">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_2_sigma_0.5_epoch_5.png" alt="Noisy 2 epoch 5">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_2_epoch_5.png" alt="Denoised 2 epoch 5">
                            <div class="image-caption">Denoised (Epoch 5)</div>
                        </div>
                    </div>

                    <h6>Sample 3 - Epoch 5</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_3_epoch_5.png" alt="Clean 3 epoch 5">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_3_sigma_0.5_epoch_5.png" alt="Noisy 3 epoch 5">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_3_epoch_5.png" alt="Denoised 3 epoch 5">
                            <div class="image-caption">Denoised (Epoch 5)</div>
                        </div>
                    </div>

                    <h6>Sample 4 - Epoch 5</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.1/clean_idx_4_epoch_5.png" alt="Clean 4 epoch 5">
                            <div class="image-caption">Clean Image</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/noisy_idx_4_sigma_0.5_epoch_5.png" alt="Noisy 4 epoch 5">
                            <div class="image-caption">Noisy (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.1/denoised_idx_4_epoch_5.png" alt="Denoised 4 epoch 5">
                            <div class="image-caption">Denoised (Epoch 5)</div>
                        </div>
                    </div>

                    <p><strong>Epoch 5 Observations:</strong> By epoch 5, the model has converged to produce high-quality denoised images. The denoised outputs are sharp, clean, and closely match the original clean digits. The model has successfully learned to project noisy images back onto the natural image manifold of MNIST digits.</p>

                    <p><strong>Comparison:</strong> Comparing epoch 1 to epoch 5 results clearly shows the training progression. The dramatic improvement in image quality demonstrates that the UNet effectively learns the inverse of the noising process through supervised training on noisy-clean image pairs.</p>

                    <h4>1.2.2 Out-of-Distribution Testing</h4>
                    <p>Testing the denoiser (trained on σ = 0.5) on different noise levels it wasn't trained on. We use the same clean test image and vary the noise level σ = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]:</p>
                    
                    <h5>Clean Image (Reference)</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.2/clean.png" alt="Clean reference">
                            <div class="image-caption">Original Clean Image</div>
                        </div>
                    </div>

                    <h5>σ = 0.0 (No Noise)</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.2/noisy_sigma_0.0.png" alt="Noisy sigma 0.0">
                            <div class="image-caption">Noisy Image (σ=0.0)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.2/denoised_sigma_0.0.png" alt="Denoised sigma 0.0">
                            <div class="image-caption">Denoised Result</div>
                        </div>
                    </div>

                    <h5>σ = 0.2</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.2/noisy_sigma_0.2.png" alt="Noisy sigma 0.2">
                            <div class="image-caption">Noisy Image (σ=0.2)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.2/denoised_sigma_0.2.png" alt="Denoised sigma 0.2">
                            <div class="image-caption">Denoised Result</div>
                        </div>
                    </div>

                    <h5>σ = 0.4</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.2/noisy_sigma_0.4.png" alt="Noisy sigma 0.4">
                            <div class="image-caption">Noisy Image (σ=0.4)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.2/denoised_sigma_0.4.png" alt="Denoised sigma 0.4">
                            <div class="image-caption">Denoised Result</div>
                        </div>
                    </div>

                    <h5>σ = 0.5 (Training Noise Level)</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.2/noisy_sigma_0.5.png" alt="Noisy sigma 0.5">
                            <div class="image-caption">Noisy Image (σ=0.5)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.2/denoised_sigma_0.5.png" alt="Denoised sigma 0.5">
                            <div class="image-caption">Denoised Result (Best Performance)</div>
                        </div>
                    </div>

                    <h5>σ = 0.6</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.2/noisy_sigma_0.6.png" alt="Noisy sigma 0.6">
                            <div class="image-caption">Noisy Image (σ=0.6)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.2/denoised_sigma_0.6.png" alt="Denoised sigma 0.6">
                            <div class="image-caption">Denoised Result</div>
                        </div>
                    </div>

                    <h5>σ = 0.8</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.2/noisy_sigma_0.8.png" alt="Noisy sigma 0.8">
                            <div class="image-caption">Noisy Image (σ=0.8)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.2/denoised_sigma_0.8.png" alt="Denoised sigma 0.8">
                            <div class="image-caption">Denoised Result</div>
                        </div>
                    </div>

                    <h5>σ = 1.0</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.2/noisy_sigma_1.0.png" alt="Noisy sigma 1.0">
                            <div class="image-caption">Noisy Image (σ=1.0)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.2/denoised_sigma_1.0.png" alt="Denoised sigma 1.0">
                            <div class="image-caption">Denoised Result</div>
                        </div>
                    </div>
                    <p>]</p>

                    <h4>1.2.3 Denoising Pure Noise</h4>
                    <p>Training a denoiser on pure Gaussian noise (ε ~ N(0, I)) where we try to predict the clean image directly from random noise. This is a much harder task than denoising partially noisy images.</p>

                    <h5>Training Loss Curve</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.3/ood_training_loss_curve.png" alt="OOD training loss">
                            <div class="image-caption">Training Loss for Pure Noise Denoising</div>
                        </div>
                    </div>

                    <h5>Out-of-Distribution Testing Results</h5>
                    <p>Testing the pure noise denoiser across different noise levels (σ). Since it was trained on pure noise, all noise levels are technically "out-of-distribution" compared to the structured noise + signal it would encounter in normal denoising:</p>
                    
                    <h6>Noisy Images at Different σ Levels</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.3/noisy_sigma_0.0.png" alt="Noisy sigma 0.0">
                            <div class="image-caption">σ = 0.0 (Clean)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/noisy_sigma_0.2.png" alt="Noisy sigma 0.2">
                            <div class="image-caption">σ = 0.2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/noisy_sigma_0.4.png" alt="Noisy sigma 0.4">
                            <div class="image-caption">σ = 0.4</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/noisy_sigma_0.5.png" alt="Noisy sigma 0.5">
                            <div class="image-caption">σ = 0.5</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/noisy_sigma_0.6.png" alt="Noisy sigma 0.6">
                            <div class="image-caption">σ = 0.6</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/noisy_sigma_0.8.png" alt="Noisy sigma 0.8">
                            <div class="image-caption">σ = 0.8</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/noisy_sigma_1.0.png" alt="Noisy sigma 1.0">
                            <div class="image-caption">σ = 1.0</div>
                        </div>
                    </div>

                    <h6>Denoised Results at Different σ Levels</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.3/denoised_sigma_0.0.png" alt="Denoised sigma 0.0">
                            <div class="image-caption">Denoised: σ = 0.0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/denoised_sigma_0.2.png" alt="Denoised sigma 0.2">
                            <div class="image-caption">Denoised: σ = 0.2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/denoised_sigma_0.4.png" alt="Denoised sigma 0.4">
                            <div class="image-caption">Denoised: σ = 0.4</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/denoised_sigma_0.5.png" alt="Denoised sigma 0.5">
                            <div class="image-caption">Denoised: σ = 0.5</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/denoised_sigma_0.6.png" alt="Denoised sigma 0.6">
                            <div class="image-caption">Denoised: σ = 0.6</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/denoised_sigma_0.8.png" alt="Denoised sigma 0.8">
                            <div class="image-caption">Denoised: σ = 0.8</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/denoised_sigma_1.0.png" alt="Denoised sigma 1.0">
                            <div class="image-caption">Denoised: σ = 1.0</div>
                        </div>
                    </div>

                    <h5>Denoising Results After Epoch 4</h5>
                    <p>Results showing both noisy inputs and denoised outputs after 4 epochs of training:</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/1.2.3/noisy_epoch_4.png" alt="Noisy epoch 4">
                            <div class="image-caption">Noisy Input (Epoch 4)</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/1.2.3/denoised_epoch_4.png" alt="Denoised epoch 4">
                            <div class="image-caption">Denoised Output (Epoch 4)</div>
                        </div>
                    </div>

                    <h5>Key Observations</h5>
                    <p>The patterns in the observed generated data are almost a combination of the training data set, with all of the shapes of the numbers layered on top of each other. It is as though it is predicting the mean of all of the training examples from the training set. This makes sense because the way we train the model is we want the model to create the output that minimizes the MSE to all training examples. Just like we talked about in lecture, how with colored images things go more grey because it’s in the middle of all of the colors, the output that minimizes the MSE of all of the training data would just be the mean of all of the training data, meaning that the same output is generated each time.</p>
                 </div>
            </div>

            <!-- Part 2: Flow Matching Model -->
            <div class="project-content">
                <h2>Part 2: Training a Flow Matching Model</h2>
                <div class="project-content-body">
                    
                    <h3>2.1 Adding Time Conditioning to UNet</h3>

                    <h3>2.2 Training the Time-Conditioned UNet</h3>
                    <p><strong>Training Details:</strong></p>
                    <ul>
                        <li>Dataset: MNIST training set</li>
                        <li>Batch size: 64</li>
                        <li>Hidden dimension D: 64</li>
                        <li>Optimizer: Adam (initial lr=1e-2)</li>
                        <li>Learning rate scheduler: Exponential decay (γ=0.1^(1/num_epochs))</li>
                        <li>Epochs: 1, 5, and 10 (trained separately to show progression)</li>
                    </ul>

                    <h4>Training Loss Curves</h4>
                    <p>We trained the time-conditioned UNet for different numbers of epochs to observe the learning progression:</p>
                    
                    <h5>1 Epoch Training</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.2/time_conditional_model_training_loss_curve_1_epochs.png" alt="Loss curve 1 epoch">
                            <div class="image-caption">Training Loss - 1 Epoch</div>
                        </div>
                    </div>

                    <h5>5 Epochs Training</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.2/time_conditional_model_training_loss_curve_5_epochs.png" alt="Loss curve 5 epochs">
                            <div class="image-caption">Training Loss - 5 Epochs</div>
                        </div>
                    </div>

                    <h5>10 Epochs Training</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.2/time_conditional_model_training_loss_curve_10_epochs.png" alt="Loss curve 10 epochs">
                            <div class="image-caption">Training Loss - 10 Epochs</div>
                        </div>
                    </div>

                    <h3>2.3 Sampling from the Time-Conditioned UNet</h3>
                    <p>Iterative denoising results using Algorithm B.2. We start from pure Gaussian noise and iteratively denoise to generate MNIST digits. These samples show the progression of generation quality as training continues:</p>
                    
                    <h4>Generated Samples - After 1 Epoch</h4>
                    <p>Early training results - digits are beginning to emerge but are not yet well-formed:</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.3/generated_1_epochs_sample_0.png" alt="1 epoch sample 0">
                            <div class="image-caption">Sample 0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_1_epochs_sample_1.png" alt="1 epoch sample 1">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_1_epochs_sample_2.png" alt="1 epoch sample 2">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_1_epochs_sample_3.png" alt="1 epoch sample 3">
                            <div class="image-caption">Sample 3</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_1_epochs_sample_4.png" alt="1 epoch sample 4">
                            <div class="image-caption">Sample 4</div>
                        </div>
                    </div>

                    <p><strong>Epoch 1 Observations:</strong> [Comment on the quality - digits are recognizable but fuzzy, edges are not sharp, overall structure is visible but details are lacking]</p>

                    <h4>Generated Samples - After 5 Epochs</h4>
                    <p>Mid-training results - digits are more recognizable and clearer:</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.3/generated_5_epochs_sample_0.png" alt="5 epochs sample 0">
                            <div class="image-caption">Sample 0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_5_epochs_sample_1.png" alt="5 epochs sample 1">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_5_epochs_sample_2.png" alt="5 epochs sample 2">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_5_epochs_sample_3.png" alt="5 epochs sample 3">
                            <div class="image-caption">Sample 3</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_5_epochs_sample_4.png" alt="5 epochs sample 4">
                            <div class="image-caption">Sample 4</div>
                        </div>
                    </div>

                    <p><strong>Epoch 5 Observations:</strong> [Comment on improvements - sharper edges, more consistent digit shapes, better overall quality compared to epoch 1]</p>

                    <h4>Generated Samples - After 10 Epochs</h4>
                    <p>Late training results - digits should be legible and reasonably well-formed:</p>
                    
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.3/generated_10_epochs_sample_0.png" alt="10 epochs sample 0">
                            <div class="image-caption">Sample 0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_10_epochs_sample_1.png" alt="10 epochs sample 1">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_10_epochs_sample_2.png" alt="10 epochs sample 2">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_10_epochs_sample_3.png" alt="10 epochs sample 3">
                            <div class="image-caption">Sample 3</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.3/generated_10_epochs_sample_4.png" alt="10 epochs sample 4">
                            <div class="image-caption">Sample 4</div>
                        </div>
                    </div>

                    <p><strong>Epoch 10 Observations:</strong> [Comment on final quality - clean, sharp digits that are clearly recognizable, though without class conditioning the model generates random digits]</p>

                    <h4>Overall Analysis</h4>
                    <p><strong>Quality Progression:</strong> The improvement from 1 to 5 to 10 epochs demonstrates that the time-conditioned UNet successfully learns to model the flow from noise to data. However, note that:</p>
                    <ul>
                        <li><strong>Random generation:</strong> Without class conditioning, we cannot control which digits are generated</li>
                        <li><strong>Digit distribution:</strong> The model may favor certain digits over others based on the training data distribution</li>
                        <li><strong>Comparison to one-step:</strong> These iterative flow matching results are significantly better than the blurry averaged outputs from Part 1.2.3's one-step denoising</li>
                        <li><strong>Need for class conditioning:</strong> To generate specific digits on demand, we need the class-conditioned version in Part 2.4-2.6</li>
                    </ul>

                    <h3>2.4 Adding Class-Conditioning to UNet</h3>
                    <p>[Explain how class conditioning is added using one-hot vectors and FCBlocks, along with 10% dropout for classifier-free guidance]</p>

                    <h3>2.5 Training the Class-Conditioned UNet</h3>
                    <p><strong>Training Details:</strong></p>
                    <ul>
                        <li>Same architecture and hyperparameters as Part 2.2</li>
                        <li>Added: Class conditioning using one-hot vectors (10 classes for digits 0-9)</li>
                        <li>Added: Unconditional dropout probability p_uncond = 0.1 (10% of the time, class conditioning is dropped)</li>
                        <li>This dropout enables classifier-free guidance during sampling</li>
                        <li>Epochs: 1, 5, and 10 (trained separately to show progression)</li>
                    </ul>

                    <h4>Training Loss Curves</h4>
                    <p>Training loss curves for the class-conditioned UNet at different training durations:</p>
                    
                    <h5>1 Epoch Training</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.5/class_conditional_model_training_loss_curve_1_epochs.png" alt="Class-conditioned loss 1 epoch">
                            <div class="image-caption">Training Loss - 1 Epoch (with class conditioning)</div>
                        </div>
                    </div>

                    <h5>5 Epochs Training</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.5/class_conditional_model_training_loss_curve_5_epochs.png" alt="Class-conditioned loss 5 epochs">
                            <div class="image-caption">Training Loss - 5 Epochs (with class conditioning)</div>
                        </div>
                    </div>

                    <h5>10 Epochs Training</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.5/class_conditional_model_training_loss_curve_10_epochs.png" alt="Class-conditioned loss 10 epochs">
                            <div class="image-caption">Training Loss - 10 Epochs (with class conditioning)</div>
                        </div>
                    </div>

                    <p>]</p>

                    <h3>2.6 Sampling from the Class-Conditioned UNet</h3>
                    <p>Using classifier-free guidance with γ = 5.0 to generate specific digit classes. The class-conditioned model allows us to control which digits are generated, unlike the time-only model which produces random digits.</p>
                    
                    <h4>Generated Samples with Learning Rate Scheduler</h4>
                    <p>Results using the exponential learning rate scheduler (γ = 0.1^(1/num_epochs)):</p>

                    <h5>After 1 Epoch (With Scheduler)</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.6/generated_1_epochs_sample_0.png" alt="1 epoch sample 0">
                            <div class="image-caption">Sample 0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_1_epochs_sample_1.png" alt="1 epoch sample 1">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_1_epochs_sample_2.png" alt="1 epoch sample 2">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_1_epochs_sample_3.png" alt="1 epoch sample 3">
                            <div class="image-caption">Sample 3</div>
                        </div>
                    </div>

                    <h5>After 5 Epochs (With Scheduler)</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.6/generated_5_epochs_sample_0.png" alt="5 epochs sample 0">
                            <div class="image-caption">Sample 0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_5_epochs_sample_1.png" alt="5 epochs sample 1">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_5_epochs_sample_2.png" alt="5 epochs sample 2">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_5_epochs_sample_3.png" alt="5 epochs sample 3">
                            <div class="image-caption">Sample 3</div>
                        </div>
                    </div>

                    <h5>After 10 Epochs (With Scheduler)</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.6/generated_10_epochs_sample_0.png" alt="10 epochs sample 0">
                            <div class="image-caption">Sample 0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_10_epochs_sample_1.png" alt="10 epochs sample 1">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_10_epochs_sample_2.png" alt="10 epochs sample 2">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_10_epochs_sample_3.png" alt="10 epochs sample 3">
                            <div class="image-caption">Sample 3</div>
                        </div>
                    </div>

                    <p><strong>Progression with Scheduler:</strong> [Observe how the generated digit quality improves from 1 to 5 to 10 epochs. Are the digits more recognizable? Are edges sharper? Is there less noise?]</p>

                    <h4>Training Loss Curves - Without Learning Rate Scheduler</h4>
                    <p>To demonstrate that we can achieve similar performance without the exponential learning rate scheduler, we trained models with alternative strategies:</p>
                    
                    <h5>Strategy: Lower initial learning rate + Weight decay</h5>
                    <p>The scheduler serves to decrease the learning rate as we go further in more epochs. This helps the model converge. Without a scheduler, we need to find another way to decrease the effective learning rate, or we could just start with a lower learning rate altogether, although this will increase the number of epochs we must run it for, because each time step we will make less of a change to our model. To solve this, I first started with a decreased learning rate, because the lower learning rate is closer to the end of the scheduler. I also added weight decay, which we are learning about in CS189. As we increase weight decay, we punish large parameters, meaning that as time goes on and the parameters increase in size, the effective learning rate is proportionally decreased, creating a sort of artificial scheduler that causes a decrease in the effective learning rate.</p>

                    <h6>1 Epoch Training (No Scheduler)</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.6/class_conditional_model_training_loss_curve_no_scheduler_1_epochs.png" alt="Loss no scheduler 1 epoch">
                            <div class="image-caption">Training Loss - 1 Epoch (No Scheduler)</div>
                        </div>
                    </div>

                    <h6>5 Epochs Training (No Scheduler)</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.6/class_conditional_model_training_loss_curve_no_scheduler_5_epochs.png" alt="Loss no scheduler 5 epochs">
                            <div class="image-caption">Training Loss - 5 Epochs (No Scheduler)</div>
                        </div>
                    </div>

                    <h6>10 Epochs Training (No Scheduler)</h6>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.6/class_conditional_model_training_loss_curve_no_scheduler_10_epochs.png" alt="Loss no scheduler 10 epochs">
                            <div class="image-caption">Training Loss - 10 Epochs (No Scheduler)</div>
                        </div>
                    </div>

                    <h4>Generated Samples - Without Learning Rate Scheduler</h4>
                    <p>Samples generated using the model trained without a learning rate scheduler:</p>
                    
                    <h5>After 1 Epoch (No Scheduler)</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.6/generated_1_epochs_sample_0_no_scheduler.png" alt="1 epoch sample 0 no scheduler">
                            <div class="image-caption">Sample 0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_1_epochs_sample_1_no_scheduler.png" alt="1 epoch sample 1 no scheduler">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_1_epochs_sample_2_no_scheduler.png" alt="1 epoch sample 2 no scheduler">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_1_epochs_sample_3_no_scheduler.png" alt="1 epoch sample 3 no scheduler">
                            <div class="image-caption">Sample 3</div>
                        </div>
                    </div>

                    <h5>After 5 Epochs (No Scheduler)</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.6/generated_5_epochs_sample_0_no_scheduler.png" alt="5 epochs sample 0 no scheduler">
                            <div class="image-caption">Sample 0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_5_epochs_sample_1_no_scheduler.png" alt="5 epochs sample 1 no scheduler">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_5_epochs_sample_2_no_scheduler.png" alt="5 epochs sample 2 no scheduler">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_5_epochs_sample_3_no_scheduler.png" alt="5 epochs sample 3 no scheduler">
                            <div class="image-caption">Sample 3</div>
                        </div>
                    </div>

                    <h5>After 10 Epochs (No Scheduler)</h5>
                    <div class="image-gallery">
                        <div class="image-container">
                            <img src="./partb/2.6/generated_10_epochs_sample_0_no_scheduler.png" alt="10 epochs sample 0 no scheduler">
                            <div class="image-caption">Sample 0</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_10_epochs_sample_1_no_scheduler.png" alt="10 epochs sample 1 no scheduler">
                            <div class="image-caption">Sample 1</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_10_epochs_sample_2_no_scheduler.png" alt="10 epochs sample 2 no scheduler">
                            <div class="image-caption">Sample 2</div>
                        </div>
                        <div class="image-container">
                            <img src="./partb/2.6/generated_10_epochs_sample_3_no_scheduler.png" alt="10 epochs sample 3 no scheduler">
                            <div class="image-caption">Sample 3</div>
                        </div>
                    </div>

                    <p><strong>Progression without Scheduler:</strong> [Observe the quality progression without the scheduler. Does it improve similarly to the with-scheduler version?]</p>

                    <h4>Comparison and Analysis</h4>
                    
                    <h5>Visual Quality Comparison</h5>
                    <p><strong>With Scheduler vs Without Scheduler:</strong></p>
                    <ul>
                        <li><strong>After 1 Epoch:</strong> [Compare the initial quality - are both models producing similar results early on?]</li>
                        <li><strong>After 5 Epochs:</strong> [Is there a noticeable difference in digit clarity and sharpness?]</li>
                        <li><strong>After 10 Epochs:</strong> [Do both approaches converge to similar quality digits by epoch 10?]</li>
                    </ul>

                    <h5>Loss Curve Analysis</h5>
                    <p><strong>Convergence Behavior:</strong> [Compare the loss curves with and without scheduler. Do they converge to similar final loss values? How does the convergence behavior differ throughout training?]</p>
                    
                    <h5>Effectiveness of Alternative Strategy</h5>
                    <p><strong>Conclusion:</strong> By using a lower initial learning rate combined with weight decay, we successfully replicate the effect of the exponential scheduler. The weight decay creates an implicit learning rate decay as parameters grow, achieving similar convergence and sample quality without explicit scheduling. This demonstrates that the exponential learning rate scheduler, while helpful, is not strictly necessary if we design appropriate alternative training strategies.</p>

                </div>
            </div>

           
        </main>

        <footer>
            <p>&copy; 2025 CS180 Portfolio • Sylvie Venuto • UC Berkeley</p>
        </footer>
    </div>
</body>
</html>
